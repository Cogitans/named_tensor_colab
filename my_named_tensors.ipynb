{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_named_tensors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzUSN3DB+bKl/5vM0jabW3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cogitans/named_tensor_colab/blob/main/my_named_tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Axes can be Done Better**\n",
        "Author: @\\_aidan\\_clark\\_ (on Twitter)\n",
        "\n",
        "The idea of naming tensor axes is a good idea, but I think not for the reasons people usually list. As a result, the existing libraries I see for named axes are either missing important features, too restrictive, or too reaching.\n",
        "\n",
        "I think the right ideas are probably out there, but haven't been put together in the right way. This is my attempt at sharing a proof-of-concept that you put the right ideas together easily. This code is **terrible**. No one should use it. I just hope to inject some ideas into the twittersphere."
      ],
      "metadata": {
        "id": "Q18rP5BPKfOL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "cellView": "form",
        "id": "O-jYLu8TKFFD",
        "tags": [
            "hide-input"
        ],
      },
      "outputs": [],
      "source": [
        "#@title Import a bunch of things (Jax + Internals + Sympy)\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import string\n",
        "from typing import Any\n",
        "import numpy as np\n",
        "import collections\n",
        "import ast\n",
        "import inspect\n",
        "from absl import app\n",
        "import textwrap\n",
        "from absl.testing import absltest\n",
        "import inspect\n",
        "import ast\n",
        "import typing\n",
        "import sympy\n",
        "import functools\n",
        "from jax._src.lib import xla_client\n",
        "\n",
        "# Importing Jax functions useful for tracing/interpreting.\n",
        "import numpy as np\n",
        "from functools import wraps\n",
        "\n",
        "from jax import core\n",
        "from jax import lax\n",
        "from jax._src.util import safe_map"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The proposal: tl;dr\n",
        "\n",
        "The goal of a named axis library should be a mechanism by which to  convert manually-added axis-names to a maximally large set of automatically-added error checks. Explicitly, the goal should **not** be to change the way we write our network code (like [some propose](http://nlp.seas.harvard.edu/NamedTensor)). These axis-names should be symbolically represented, with the mechanisms in place to detect a large set of useful transformations."
      ],
      "metadata": {
        "id": "iefBisHaK4uV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this colab I'm going to implement a JAX-transformation called @shapecheck which does what I want it to. Nothing about what I suggest is tied to JAX (or a static graph-esque-setup) in any way, it was just easy for me to implement."
      ],
      "metadata": {
        "id": "CTU3cTKSP739"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Shapecheck code (don't look it's really horrible...)\n",
        "\n",
        "\n",
        "one_letter_symbols = {}\n",
        "for c in string.ascii_lowercase:\n",
        "    one_letter_symbols[c] = sympy.Symbol(c)\n",
        "for c in string.ascii_uppercase:\n",
        "    one_letter_symbols[c] = sympy.Symbol(c)\n",
        "\n",
        "class _Shape:\n",
        "\n",
        "    def __init__(self, shape_names):\n",
        "        self.shape_names = []\n",
        "        for x in shape_names:\n",
        "            if isinstance(x, int):\n",
        "                self.shape_names.append(x)\n",
        "            elif x == \":\":\n",
        "                self.shape_names.append(x)\n",
        "            else:\n",
        "                self.shape_names.append(sympy.sympify(x, locals=one_letter_symbols))\n",
        "\n",
        "    def register(self, set_by, value_shape):\n",
        "        for i, name in enumerate(self.shape_names):\n",
        "            _global_defs_stack[-1].register(set_by, name, value_shape[i])\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"Shape{self.shape_names}\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.shape_names)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.shape_names[i]\n",
        "\n",
        "class _Dims:\n",
        "    \n",
        "    def __getitem__(self, ks: str) -> None:\n",
        "        return _Shape(ks)\n",
        "\n",
        "\n",
        "S = _Dims()\n",
        "\n",
        "class _LocalStack:\n",
        "    def __init__(self):\n",
        "        self.stack = {}\n",
        "\n",
        "    def register(self, set_by, name, value):\n",
        "        if name not in self.stack:\n",
        "            self.stack[name] = [(set_by, value)]\n",
        "        else:\n",
        "            self.stack[name].append((set_by, value))\n",
        "    def check(self):\n",
        "        error_msg = \"\"\n",
        "        for name in self.stack.keys():\n",
        "            values = []\n",
        "            for sb, v in self.stack[name]:\n",
        "                values.append(v)\n",
        "            if not all(v == values[0] for v in values):\n",
        "                s = f\"Inconsistent axis naming.\\n\"\n",
        "                for sb, v in self.stack[name]:\n",
        "                    s += f\"\\t\\t{name} set to {v} by {sb}\\n\"\n",
        "                s += \"\\n\\n\"\n",
        "                error_msg += s\n",
        "        if error_msg:\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "_global_defs_stack = []\n",
        "\n",
        "def namedtensors_check():\n",
        "    def inner_wrapper(fun):\n",
        "\n",
        "        def inner_fun(*args, **kwargs):\n",
        "            assert len(args) == 0  # We don't want to support this right now\n",
        "            _global_defs_stack.append(_LocalStack())\n",
        "\n",
        "            for k, v in typing.get_type_hints(fun).items():\n",
        "                if isinstance(v, _Shape) and k != \"return\":\n",
        "                    value = kwargs[k]\n",
        "                    v.register(k, value.shape)\n",
        "            _global_defs_stack[-1].check()\n",
        "\n",
        "            out = fun(*args, **kwargs)\n",
        "            \n",
        "            return_type = typing.get_type_hints(fun)[\"return\"]\n",
        "            if isinstance(return_type, _Shape):\n",
        "                return_type.register(\"return\", out.shape)\n",
        "            _global_defs_stack[-1].check()\n",
        "\n",
        "            _global_defs_stack.pop()\n",
        "            return out\n",
        "        return inner_fun\n",
        "    return inner_wrapper\n",
        "\n",
        "\n",
        "def nameshape_or_trueshape_equal(i, xnameshape, ynameshape, xtrueshape, ytrueshape):\n",
        "    x_i, y_i = xnameshape, ynameshape\n",
        "    true_xi, true_yi = xtrueshape, ytrueshape\n",
        "    if not isinstance(x_i, int) and not isinstance(y_i, int):\n",
        "        if x_i == y_i:\n",
        "            return x_i\n",
        "        else:\n",
        "            raise ValueError(f\"In output position {i}, shapes {x_i} and {y_i} do not match.\")\n",
        "    elif isinstance(x_i, sympy.Symbol):\n",
        "        if true_xi == y_i:\n",
        "            return x_i\n",
        "        else:\n",
        "            raise ValueError(f\"In output position {i}, shapes {x_i} and {y_i} do not match.\")\n",
        "    elif isinstance(y_i, sympy.Symbol):\n",
        "        if x_i == true_yi:\n",
        "            return y_i\n",
        "        else:\n",
        "            raise ValueError(f\"In output position {i}, shapes {x_i} and {y_i} do not match.\")\n",
        "    else:\n",
        "        assert x_i == true_xi and y_i == true_yi\n",
        "        if x_i == y_i:\n",
        "            return y_i\n",
        "        else:\n",
        "            raise ValueError(f\"In output position {i}, shapes {x_i} and {y_i} do not match.\")\n",
        "\n",
        "\n",
        "def _add_shape_fn(x_val_shape, y_val_shape, x_shape, y_shape):\n",
        "    output_shape = []\n",
        "    for i in range(max(len(x_shape), len(y_shape))):\n",
        "        xj = len(x_shape) - 1 - i\n",
        "        yj = len(y_shape) - 1 - i\n",
        "        if xj < 0:\n",
        "            output_shape.append(y_shape[yj])\n",
        "            continue\n",
        "        if yj < 0:\n",
        "            output_shape.append(y_shape[xj])\n",
        "            continue\n",
        "        x_i, y_i = x_shape[xj], y_shape[yj]\n",
        "        output_shape.append(nameshape_or_trueshape_equal(xj, x_shape[xj], y_shape[yj], x_val_shape[xj], y_val_shape[yj]))\n",
        "    return output_shape[::-1]\n",
        "\n",
        "\n",
        "def _equal_shape(x_shape, y_shape):\n",
        "    return all(x_shape[i] == y_shape[i] for i in range(len(x_shape)))\n",
        "\n",
        "def _concatenate_shape_fn(x_val_shape, y_val_shape, x_shape, y_shape, dimension):\n",
        "    assert len(x_val_shape) == len(y_val_shape)\n",
        "    output_shape = [None for _ in range(len(x_val_shape))]\n",
        "    for i in range(len(x_val_shape)):\n",
        "        if i != dimension:\n",
        "            output_shape[i] = nameshape_or_trueshape_equal(\n",
        "                i, x_shape[i], y_shape[i], x_val_shape[i], y_val_shape[i])\n",
        "    output_shape[dimension] = x_shape[dimension] + y_shape[dimension]\n",
        "    return output_shape\n",
        "\n",
        "def _register_shape_shape_fn(x_val_shape, x_shape, shape, require_variable_matching):\n",
        "    output_shape = []\n",
        "    for i in range(len(x_val_shape)):\n",
        "        output_shape.append(check_shapes_work({}, x_val_shape[i], x_shape[i], shape[i], i, require_variable_matching))\n",
        "        # if isinstance(x_shape[i], _Shape):\n",
        "        #     if x_shape[i] == shape[i]:\n",
        "        #        output_shape.append(x_shape[i])\n",
        "        #     else:\n",
        "        #         raise ValueError((x_val_shape, x_shape, shape))\n",
        "        # else:\n",
        "        #     output_shape.append(shape[i])\n",
        "    return _Shape(output_shape)\n",
        "\n",
        "def _transpose_shape_fn(x_val_shape, x_shape, permutation):\n",
        "    return [x_shape[p] for p in permutation]\n",
        "\n",
        "\n",
        "def _slice_shape_fn(\n",
        "    x_val_shape, x_shape, start_indices, limit_indices, strides,\n",
        "):\n",
        "    if strides is not None:\n",
        "        raise NotImplementedError()\n",
        "    return [x_shape[i] - (x_val_shape[i] - (limit_indices[i] - start_indices[i]))\n",
        "            for i, p in enumerate(range(len(x_shape)))]\n",
        "\n",
        "_shape_fns = {\n",
        "    \"add\": _add_shape_fn,\n",
        "    \"concatenate\": _concatenate_shape_fn,\n",
        "    \"shapecheck\": _register_shape_shape_fn,\n",
        "    \"transpose\": _transpose_shape_fn,\n",
        "    \"slice\": _slice_shape_fn,\n",
        "}\n",
        "\n",
        "\n",
        "def check_shapes_work(known_shapes, true_shape_i, labelled_shape_i, assigning_shape_i, i, require_variable_matching):\n",
        "    \"\"\"Error if this is an invalid assignment, else return the new shape.\"\"\"\n",
        "    # This is a bad name so lets just change it.\n",
        "    allow_new_variables = not require_variable_matching\n",
        "\n",
        "    def maybe_evaluate(x):\n",
        "        if isinstance(x, int):\n",
        "            return x\n",
        "        else:\n",
        "            return x.subs(known_shapes.items())\n",
        "\n",
        "    # We're checking whether assinging_shape_i is a valid name for an axis which is previously\n",
        "    # called labelled_shape_i and has the actual size true_shape_i.\n",
        "\n",
        "    # There are a couple of cases.\n",
        "\n",
        "    # 1) If assigning_shape_i == \":\", anything goes. Use the previous value.\n",
        "    # import pdb; pdb.set_trace()\n",
        "    if assigning_shape_i == \":\":\n",
        "        return labelled_shape_i\n",
        "\n",
        "    # 2) If assigning_shape_i is a number, only allow it if it's a) correct\n",
        "    #    and b) it's not shadowing a non-numeric previous label.\n",
        "    elif isinstance(assigning_shape_i, int):\n",
        "        if not isinstance(labelled_shape_i, int):\n",
        "            raise ValueError(\n",
        "                f\"User assigned shape {assigning_shape_i} shadowing previous \"\n",
        "                f\"label {labelled_shape_i} with value {maybe_evaluate(labelled_shape_i)}.\")\n",
        "        if labelled_shape_i != assigning_shape_i:\n",
        "            raise ValueError(\n",
        "                f\"User assigned shape {assigning_shape_i} does not equal previous \"\n",
        "                f\"value of {labelled_shape_i}.\"\n",
        "            )\n",
        "        return assigning_shape_i\n",
        "\n",
        "    # 3) We're assigning a shape which is symbolic.\n",
        "    else:\n",
        "        # In the symbolic case, we basically have two cases.\n",
        "        \n",
        "        # 1) labelled_shape_i is numeric.\n",
        "        if isinstance(labelled_shape_i, int):\n",
        "            # In this case, assigning_shape_i needs to be a simple variable.\n",
        "            if not isinstance(assigning_shape_i, sympy.Symbol):\n",
        "                raise ValueError(\n",
        "                    f\"User assigning complex shape {assigning_shape_i} to \"\n",
        "                    f\"unlabelled axis with size {labelled_shape_i}.\"\n",
        "                )\n",
        "            if allow_new_variables:\n",
        "                if assigning_shape_i not in known_shapes:\n",
        "                    # We're allowed to define a new variable and this is that!\n",
        "                    # So put it in and return the new name!\n",
        "                    known_shapes[assigning_shape_i] = true_shape_i\n",
        "                    return assigning_shape_i\n",
        "                else:\n",
        "                    # We need to check that the value we're assigning is equal.\n",
        "                    if known_shapes[assigning_shape_i] == true_shape_i:\n",
        "                        return assigning_shape_i\n",
        "                    else:\n",
        "                        raise ValueError(\n",
        "                            f\"User assigning {assigning_shape_i} to {true_shape_i} \"\n",
        "                            f\"but is already assigned to {known_shapes[assigning_shape_i]}.\"\n",
        "                        )\n",
        "            else:\n",
        "                \n",
        "                if assigning_shape_i not in known_shapes:\n",
        "                    raise ValueError(\n",
        "                        f\"User assigning new axis name {assigning_shape_i} in a check-statement.\"\n",
        "                    )\n",
        "                else:\n",
        "                    # This is the same second case as above.\n",
        "                    # We need to check that the value we're assigning is equal.\n",
        "                    if known_shapes[assigning_shape_i] == true_shape_i:\n",
        "                        return assigning_shape_i\n",
        "                    else:\n",
        "                        raise ValueError(\n",
        "                            f\"User assigning {assigning_shape_i} to {true_shape_i} \"\n",
        "                            f\"but is already assigned to {known_shapes[assigning_shape_i]}.\"\n",
        "                        )\n",
        "\n",
        "        # 2) In this case, labelled_shape_i is symbolic, so we're assigning\n",
        "        #    a symbol to an axis which already has a symbolic label.\n",
        "        else:\n",
        "            # It's easiest to split this up into cases too.\n",
        "\n",
        "            # 1) Both are simple symbols.\n",
        "            if isinstance(assigning_shape_i, sympy.Symbol) and isinstance(labelled_shape_i, sympy.Symbol):\n",
        "                if assigning_shape_i == labelled_shape_i:\n",
        "                    # Easy, this is trivial!\n",
        "                    return assigning_shape_i\n",
        "                else:\n",
        "                    # Maybe this is okay...\n",
        "                    if allow_new_variables and assigning_shape_i not in known_shapes:\n",
        "                        # This is allowed! It's just shadowing....\n",
        "                        known_shapes[assigning_shape_i] = true_shape_i\n",
        "                        return assigning_shape_i\n",
        "                    elif not allow_new_variables and assigning_shape_i not in known_shapes:\n",
        "                        raise ValueError(\n",
        "                            f\"User assigning new axis name {assigning_shape_i} in a check-statement.\"\n",
        "                        )\n",
        "                    else:\n",
        "                        if maybe_evaluate(assigning_shape_i) == maybe_evaluate(labelled_shape_i):\n",
        "                            raise ValueError(\n",
        "                                f\"User incorrectly labelling axis {labelled_shape_i}={maybe_evaluate(labelled_shape_i)} \"\n",
        "                                f\"as {assigning_shape_i}={maybe_evaluate(assigning_shape_i)} even though their shapes match.\"\n",
        "                            )\n",
        "                        else:\n",
        "                            raise ValueError(\n",
        "                                f\"User incorrectly labelling axis {labelled_shape_i}={maybe_evaluate(labelled_shape_i)} \"\n",
        "                                f\"as {assigning_shape_i}={maybe_evaluate(assigning_shape_i)}.\"\n",
        "                            )\n",
        "            \n",
        "            # 2) labelled_shape_i is an expression.\n",
        "            #    in this case, we can only rename it with a new value.\n",
        "            elif isinstance(labelled_shape_i, sympy.Expr):\n",
        "                if allow_new_variables:\n",
        "                    if isinstance(assigning_shape_i, sympy.Symbol) and assigning_shape_i not in known_shapes:\n",
        "                        known_shapes[assigning_shape_i] = true_shape_i\n",
        "                        return assigning_shape_i\n",
        "                    elif isinstance(assigning_shape_i, sympy.Symbol):\n",
        "                        if assigning_shape_i == labelled_shape_i:\n",
        "                            return assigning_shape_i\n",
        "                        else:\n",
        "                            raise ValueError(\n",
        "                                f\"Cannot shadow axis {labelled_shape_i} with existing variable {assigning_shape_i}.\"\n",
        "                            )\n",
        "                    else:\n",
        "                        if assigning_shape_i == labelled_shape_i:\n",
        "                            return assigning_shape_i\n",
        "                        else:\n",
        "                            raise ValueError(\n",
        "                                f\"Cannot shadow expression {labelled_shape_i} with expression {assigning_shape_i}.\")\n",
        "                else:\n",
        "                    if assigning_shape_i == labelled_shape_i:\n",
        "                        return assigning_shape_i\n",
        "                    elif assigning_shape_i in known_shapes:\n",
        "                        raise ValueError(\n",
        "                            f\"User assigned label {assigning_shape_i} does not match {labelled_shape_i}.\"\n",
        "                        )\n",
        "                    else:\n",
        "                        raise ValueError(\n",
        "                            f\"Axis {labelled_shape_i} cannot be named to an existing variable.\"\n",
        "                        )\n",
        "            else:\n",
        "                raise ValueError(\"BAD\")\n",
        "\n",
        "\n",
        "def register_shapes_with_values(known_shapes, invals, inshapes, shape, require_variable_matching):\n",
        "    # For each dim....\n",
        "    for i in range(len(shape)):\n",
        "        true_shape_i = invals.shape[i]\n",
        "        labelled_shape_i = inshapes[i]\n",
        "        assigning_shape_i = shape[i]\n",
        "        check_shapes_work(known_shapes, true_shape_i, labelled_shape_i, assigning_shape_i, i, require_variable_matching)\n",
        "    \n",
        "\n",
        "def custom_eval_jaxpr(jaxpr, consts, *args):\n",
        "  # Mapping from variable -> value\n",
        "  env = {}\n",
        "  shape_env = {}\n",
        "  known_shapes = {}\n",
        "#   assert len(argshapes) == len(args)\n",
        "  \n",
        "  def read(var):\n",
        "    # Literals are values baked into the Jaxpr\n",
        "    if type(var) is core.Literal:\n",
        "      val = var.val\n",
        "      return val, None\n",
        "    else:\n",
        "        val = env[var]\n",
        "        if var in shape_env:\n",
        "            shape = shape_env[var]\n",
        "        else:\n",
        "            shape = val.shape\n",
        "        return val, shape\n",
        "\n",
        "  def write(var, val, valshape=None):\n",
        "    env[var] = val\n",
        "    if valshape:\n",
        "        shape_env[var] = valshape\n",
        "\n",
        "  # Bind args and consts to environment\n",
        "  safe_map(write, jaxpr.invars, args)\n",
        "  safe_map(write, jaxpr.constvars, consts)\n",
        "\n",
        "  # Loop through equations and evaluate primitives using `bind`\n",
        "  for eqn_i, eqn in enumerate(jaxpr.eqns):\n",
        "    # Read inputs to equation from environment\n",
        "    invals, inshapes = zip(*safe_map(read, eqn.invars))\n",
        "\n",
        "    # `bind` is how a primitive is called\n",
        "    outvals = eqn.primitive.bind(*invals, **eqn.params)\n",
        "    if eqn.primitive.name == \"shapecheck\":\n",
        "        safe_map(functools.partial(register_shapes_with_values, known_shapes, **eqn.params), invals, inshapes)\n",
        "    if eqn.primitive.name in _shape_fns:\n",
        "        outshapes = _shape_fns[eqn.primitive.name](*[v.shape for v in invals], *inshapes, **eqn.params)\n",
        "    else:\n",
        "        outshapes = [None for v in outvals] if eqn.primitive.multiple_results else None\n",
        "    # Primitives may return multiple outputs or not\n",
        "    if not eqn.primitive.multiple_results: \n",
        "      outvals = [outvals]\n",
        "      outshapes = [outshapes]\n",
        "\n",
        "    # Write the results of the primitive into the environment\n",
        "    safe_map(write, eqn.outvars, outvals, outshapes) \n",
        "  # Read the final result of the Jaxpr from the environment\n",
        "  return zip(*safe_map(read, jaxpr.outvars))\n",
        "\n",
        "\n",
        "def _shapecheck_shape_rule(*operands, **kwargs):\n",
        "    return operands[0].shape\n",
        "\n",
        "def _shapecheck_dtype_rule(*operands, **kwargs):\n",
        "  return operands[0].dtype\n",
        "\n",
        "\n",
        "# The concatenate_p masking rule requires use of a while-loop construct and so\n",
        "# is defined in lax_control_flow.py\n",
        "\n",
        "shapecheck_p = jax._src.lax.lax.standard_primitive(\n",
        "    _shapecheck_shape_rule, _shapecheck_dtype_rule, 'shapecheck')\n",
        "\n",
        "def shapecheck__xla_translation(ctx, avals_in, avals_out, xc, **kwargs):\n",
        "  \"\"\"The compilation to XLA of the primitive.\n",
        "\n",
        "  Given an XlaBuilder and XlaOps for each argument, return the XlaOp for the\n",
        "  result of the function.\n",
        "\n",
        "  Does not need to be a JAX-traceable function.\n",
        "  \"\"\"\n",
        "  return [xc]\n",
        "\n",
        "# Now we register the XLA compilation rule with JAX\n",
        "# TODO: for GPU? and TPU?\n",
        "from jax.interpreters import xla\n",
        "xla.register_translation(shapecheck_p, shapecheck__xla_translation, platform='cpu')\n",
        "\n",
        "def bind_shape(x, shape, require_variable_matching):\n",
        "  return shapecheck_p.bind(*[x], shape=shape, require_variable_matching=require_variable_matching)\n",
        "\n",
        "def register_shape(x, shape):\n",
        "    return bind_shape(x, shape, False)\n",
        "\n",
        "def check_shape(x, shape):\n",
        "    return bind_shape(x, shape, True)\n",
        "\n",
        "\n",
        "\n",
        "def shapecheck(f):\n",
        "    def wrapped_fun(*args, **kwargs):\n",
        "        assert not kwargs, \"Not supported\"\n",
        "\n",
        "        if \"return\" in typing.get_type_hints(f):\n",
        "            def g(*args):\n",
        "                new_args = []\n",
        "                for i, (k, v) in enumerate(inspect.signature(f).parameters.items()):\n",
        "                    if isinstance(v.annotation, _Shape):\n",
        "                        new_args.append(register_shape(args[i], v.annotation))\n",
        "                    else:\n",
        "                        new_args.append(args[i])\n",
        "                o = f(*new_args, **kwargs)\n",
        "                return check_shape(o, typing.get_type_hints(f)[\"return\"])\n",
        "        else:\n",
        "            def g(*args):\n",
        "                new_args = []\n",
        "                for i, (k, v) in enumerate(inspect.signature(f).parameters.items()):\n",
        "                    if isinstance(v.annotation, _Shape):\n",
        "                        new_args.append(register_shape(args[i], v.annotation))\n",
        "                    else:\n",
        "                        new_args.append(args[i])\n",
        "                return f(*new_args, **kwargs)\n",
        "\n",
        "        closed_jaxpr = jax.make_jaxpr(g)(*args)\n",
        "        outvals, outshapes = custom_eval_jaxpr(\n",
        "            closed_jaxpr.jaxpr, closed_jaxpr.literals,\n",
        "            *args)\n",
        "        return outvals[0]\n",
        "    return wrapped_fun\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KvA23TnNOOht"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown We're just going to share some basic input variables for simplicity.\n",
        "\n",
        "k = jax.random.PRNGKey(666)\n",
        "k, k2, k3, k4 = jax.random.split(k, 4)\n",
        "\n",
        "x = jax.random.normal(k, shape=(10, 15))\n",
        "y = jax.random.normal(k2, shape=(10, 15))\n",
        "z = jax.random.normal(k3, shape=(10, 15))\n",
        "w = jax.random.normal(k3, shape=(15, 15))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5H7fRNw7QXWR"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Examples\n",
        "#@markdown First of all, our transformation shouldn't require any names whatsoever and doesn't prevent normal indexing. \n",
        "\n",
        "@shapecheck\n",
        "def example_one(x, y):\n",
        "  return (x[:, 0:3] + y[0:3, 5:].T).sum(0)\n",
        "\n",
        "example_one(x, y).block_until_ready()\n",
        "print(f\"Example One works.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXxx42zpKORG",
        "outputId": "1b9bae3b-a3ba-4407-df85-a3ae64d02aa6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example One works.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Rather, it provides an optional method by which to **labe**l certain axes.\n",
        "\n",
        "# Here, we're labelling that X has two axes and\n",
        "# we're calling them N and M.\n",
        "@shapecheck\n",
        "def example_two_a(x, y):\n",
        "  x = register_shape(x, S[\"N\", \"M\"])\n",
        "  return (x[:, 0:3] + y[0:3, 5:].T).sum(0)\n",
        "\n",
        "#It's pretty easy to simplify the syntax too.\n",
        "\n",
        "@shapecheck\n",
        "def example_two_b(x: S[\"N\", \"M\"], y):\n",
        "  return (x[:, 0:3] + y[0:3, 5:].T).sum(0)\n",
        "\n",
        "example_two_b(x, y).block_until_ready()\n",
        "print(f\"Example Two works.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYsHJ1qoQkVb",
        "outputId": "bc771453-104c-4aba-80aa-0868f58975fd"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example Two works.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this last example we've labelled one of the input tensors with axes N and M. Note two important things:\n",
        "1.   We're still able to index the normal way\n",
        "2.   shapecheck isn't complaining about the axes being mixed.\n",
        "\n",
        "The second point is important. The system should explicitly support named and unnamed axes in the following way\n",
        "\n",
        "*   An unnamed axis should always be able to interact with any unnamed axis.\n",
        "*   A named axis should **always** be able to interact with an unnamed axis if the true shapes match.\n",
        "* Two named axes can only interact with each other if they match names.\n",
        "\n",
        "This allows a simple on-ramp of complexity, consider the next exampples:\n",
        "\n"
      ],
      "metadata": {
        "id": "MoEyRhudTGKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@shapecheck\n",
        "def example_three_a(x: S[\"N\", \"M\"], y):\n",
        "  # Named axis interacting with unnamed axis: fine!\n",
        "  z = x + y\n",
        "  \n",
        "  # And the resulting tensor keeps the axes:\n",
        "  return check_shape(z, S[\"N\", \"M\"])\n",
        "\n",
        "example_three_a(x, y).sum().block_until_ready()\n",
        "print(f\"Example 3a works.\")\n",
        "\n",
        "@shapecheck\n",
        "def example_three_b(x: S[\"N\", \"M\"], y):\n",
        "  # Named axis interacting with unnamed axis: fine!\n",
        "  z = x + y\n",
        "  \n",
        "  # And the resulting tensor keeps the axes:\n",
        "  z = check_shape(z, S[\"N\", \"M\"])\n",
        "\n",
        "  # And incorrecting asserting them is a problem!\n",
        "  return check_shape(z, S[\"M\", \"N\"])\n",
        "\n",
        "try:\n",
        "  print(f\"This isn't fine: {example_three_b(x, y).sum()}\")\n",
        "except ValueError as e:\n",
        "  assert str(e) == \"User incorrectly labelling axis N=10 as M=15.\"\n",
        "  # Note a non-transformation-based implementation would error in\n",
        "  # the function not outside of it. Again, this is just easiest.\n",
        "  print(f\"Example 3b errors.\")\n",
        "\n",
        "@shapecheck\n",
        "def example_four_a(x: S[\"N\", \"M\"], y: S[\"N\", \"M\"]):\n",
        "  # Named axis interacting with named axis: fine!\n",
        "  z = x + y\n",
        "  \n",
        "  # And the resulting tensor keeps the axes:\n",
        "  return check_shape(z, S[\"N\", \"M\"])\n",
        "\n",
        "example_four_a(x, y).block_until_ready()\n",
        "print(f\"Example 4a works.\")\n",
        "\n",
        "@shapecheck\n",
        "def example_four_b(x: S[\"N\", \"M\"], y: S[\"S\", \"T\"]):\n",
        "  # Named axis interacting with different named axis: bad!\n",
        "  return x + y\n",
        "  \n",
        "try:\n",
        "  print(f\"This isn't fine: {example_four_b(x, y).sum()}\")\n",
        "except ValueError as e:\n",
        "  assert str(e) == \"In output position 1, shapes M and T do not match.\"\n",
        "  print(f\"Example 4b errors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUNyIECASw-G",
        "outputId": "009fbe05-200f-40c2-b158-ab1226bb7288"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 3a works.\n",
            "Example 3b errors.\n",
            "Example 4a works.\n",
            "Example 4b errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also add a little more syntactic sugar to check output shapes:"
      ],
      "metadata": {
        "id": "SYmxC5FlnHuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@shapecheck\n",
        "def example_five(x: S[\"N\", \"M\"], y: S[\"N\", \"M\"]) -> S[\"M\", \"N\"]:\n",
        "  # Named axis interacting with named axis: fine!\n",
        "  return (x + y).T\n",
        "\n",
        "example_five(x, y).block_until_ready()\n",
        "print(f\"Example five works.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2xrkU0ynMRW",
        "outputId": "c6b7cd1d-6957-422e-e061-267de75d256d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example five works.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, if you *wanted* to add some static types here to help your analysis, you could. But this is explicitly not a design goal. "
      ],
      "metadata": {
        "id": "lsKz88ovnbTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_M_Matrix = S[\"N\", \"M\"]\n",
        "M_N_Matrix = S[\"M\", \"N\"]\n",
        "\n",
        "z: M_N_Matrix = z.T\n",
        "\n",
        "@shapecheck\n",
        "def example_six(x: N_M_Matrix, y: N_M_Matrix) -> M_N_Matrix:\n",
        "  # Named axis interacting with named axis: fine!\n",
        "  return (x + y).T\n",
        "\n",
        "try:\n",
        "  print(f\"This is fine: {example_six(z, y).sum()}\")\n",
        "except TypeError as e:\n",
        "  assert str(e) == \"add got incompatible shapes for broadcasting: (15, 10), (10, 15).\"\n",
        "  # Static analysis could error on this call before the error is thrown!\n",
        "  print(\"Example 6 errors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtxfddgWnaBj",
        "outputId": "ff753d6b-09d6-488c-f788-a9913aa9f8bf"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 6 errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far this is pretty much any other named tensor library (perhaps being a little more lenient about named axes and non-named axes). The cool thing is though, we've implemented this symbolic axis naming scheme, which lets us do really neat things, like automatically label slices and stacks:"
      ],
      "metadata": {
        "id": "ph5tXghRmzg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@shapecheck\n",
        "def example_seven(x: S[\"N\", \"M\"], y: S[\"N\", \"M\"]) -> S[\"2*N\", \"M\"]:\n",
        "  return jnp.concatenate([x, y], 0)\n",
        "\n",
        "example_seven(x, y).block_until_ready()\n",
        "print(f\"Example seven works!\")\n",
        "\n",
        "@shapecheck\n",
        "def example_eight(x: S[\"N\", \"M\"], y: S[\"M\", \"M\"]) -> S[\"N + M\", \"M\"]:\n",
        "  return jnp.concatenate([x, y], 0)\n",
        "\n",
        "example_eight(x, w).block_until_ready()\n",
        "print(f\"Example eight works!\")\n",
        "\n",
        "@shapecheck\n",
        "def example_nine(x: S[\"N\", \"M\"]) -> S[\"N-1\", \"M\"]:\n",
        "  x1 = jax.lax.slice(x, [0, 0], [x.shape[0] - 1, x.shape[1]])\n",
        "  x2 = jax.lax.slice(x, [1, 0], [x.shape[0], x.shape[1]])\n",
        "  return x1 + x2\n",
        "\n",
        "example_nine(x).block_until_ready()\n",
        "print(f\"Example nine works!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIwL0SXUoF-p",
        "outputId": "66d3b88d-4606-4c1b-8c17-a3487219c450"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example seven works!\n",
            "Example eight works!\n",
            "Example nine works!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isn't that cool! \n",
        "\n",
        "We can go further. What if you wanted those two axes to actually represent different values? For instance, if it was an RL problem and you wanted one to represent targets and one to represent inputs, you wouldn't want to mix those up!\n",
        "\n",
        "Our syntax actually allows for this via axis name shadowing!"
      ],
      "metadata": {
        "id": "_ppOTOb7pmx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@shapecheck\n",
        "def example_ten_a(x: S[\"N\", \"M\"]) -> S[\"N-1\", \"M\"]:\n",
        "  x1 = jax.lax.slice(x, [0, 0], [x.shape[0] - 1, x.shape[1]])\n",
        "  x1 = register_shape(x1, S[\"Ntm1\", \"M\"])\n",
        "  x2 = jax.lax.slice(x, [1, 0], [x.shape[0], x.shape[1]])\n",
        "  x2 = register_shape(x2, S[\"Ntp1\", \"M\"])\n",
        "  return x1 + x2\n",
        "\n",
        "try:\n",
        "  print(f\"This is fine: {example_ten_a(x).sum()}\")\n",
        "except ValueError as e:\n",
        "  assert str(e) == \"In output position 0, shapes Ntm1 and Ntp1 do not match.\"\n",
        "  print(\"Example 10A errors!\")\n",
        "\n",
        "# You _really_ want to be able to make this even more concise, and write:\n",
        "@shapecheck\n",
        "def example_ten_b(x: S[\"N\", \"M\"]) -> S[\"N-1\", \"M\"]:\n",
        "  x1: S[\"Ntm1\", \"M\"] = jax.lax.slice(x, [0, 0], [x.shape[0] - 1, x.shape[1]])\n",
        "  x2: S[\"Ntp1\", \"M\"] = jax.lax.slice(x, [1, 0], [x.shape[0], x.shape[1]])\n",
        "  return x1 + x2\n",
        "# Unfortunately Python is dumb and doesn't pick up on arbitrary variable annotation.\n",
        "# You can actually make this work but it involves AST hacking and I have too much\n",
        "# dignity to link my crappy hacks here."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjW7oW1UoIwQ",
        "outputId": "ed42a8e2-6881-4688-ead1-9bf12c86fd11"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 10A errors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To conclude....\n",
        "\n",
        "In a sense this is all just a weird random idea dump, but want I want to convey is that it's possible to build a really simple and clean named axis system that's minimally intrusive and yet allows you to do really cool things.\n",
        "\n",
        "I would really encourage people who see this and are interested in writing named tensor axes to support the sorts of features I've described (symbolic names!!!!). I'd also encourage them to limit the scope of what their trying to accomplish. Too many of the libraries I see try to do too much (e.g. xmap pushing named axes toe-in-toe with a complex distribution mentality) or have too strong an opinion (want all indexing to be named).\n",
        "\n",
        "I hope you found this interesting!"
      ],
      "metadata": {
        "id": "aaJKFcftqou9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "skOTbIuUrlkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Things I didn't implement but would be trivial**\n",
        "\n",
        "\n",
        "*   Nested shapecheck\n",
        "*   \"...\" support for arbitrary rank\n",
        "*   Support for vmap/pmap/etc\n",
        "*   Constraint setting, i.e. explicitly saying M = 25*N and letting ops work across different axes which satisfy those constraints.\n",
        "\n",
        "**Things I think are non-obvious to figure out**\n",
        "\n",
        "*When should slice outputs be constant or symbolic?*\n",
        "\n",
        "For instance, if x: S[N, M], then x[1:x.shape[0], ...] should probably be S[N-1, M] but x[:3, :3] should probably be S[3, 3]. It's non-obvious to me if there's a good rule for how to pick one over the other or if that should be user-selected.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1--IPwMcrl49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hSMNG5fHsWlH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
